{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1aa4dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_text in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (2.10.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow<2.11,>=2.10.0 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow_text) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow_text) (0.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (65.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (4.4.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (16.0.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.14.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.19.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.54.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.23.5)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (23.5.26)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.19.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.28.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.26.14)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\akash\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in c:\\users\\akash\\anaconda3\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow_hub) (3.19.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.23.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>641</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Message                                                            \\\n",
       "           count unique                                                top   \n",
       "Category                                                                     \n",
       "ham         4825   4516                             Sorry, I'll call later   \n",
       "spam         747    641  Please call our customer service representativ...   \n",
       "\n",
       "               \n",
       "         freq  \n",
       "Category       \n",
       "ham        30  \n",
       "spam        4  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text    \n",
    "\n",
    "!pip install --user tensorflow_text\n",
    "\n",
    "\n",
    "!pip install tensorflow_hub\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\akash\\Python_DL\\project_data\\Data.csv')\n",
    "# \"C:\\Users\\akash\\Python_DL\\project_data\\Data.csv\"\n",
    "df.head(5)\n",
    "\n",
    "df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e679208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class KerasLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, hub_url, **kwargs):\n",
    "#         super(KerasLayer, self).__init__(**kwargs)\n",
    "#         self.hub_url = hub_url\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.bert_layer = hub.KerasLayer(self.hub_url, trainable=True)\n",
    "#         super(KerasLayer, self).build(input_shape)\n",
    "\n",
    "#     def call(self, inputs, **kwargs):\n",
    "#         return self.bert_layer(inputs, **kwargs)\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = super(KerasLayer, self).get_config()\n",
    "#         config['hub_url'] = self.hub_url\n",
    "#         return config\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_config(cls, config):\n",
    "#         return cls(hub_url=config['hub_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2fdb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for Class spam:\n",
      "     Category                                            Message\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "5        spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "8        spam  WINNER!! As a valued network customer you have...\n",
      "9        spam  Had your mobile 11 months or more? U R entitle...\n",
      "11       spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "...       ...                                                ...\n",
      "5537     spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540     spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547     spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566     spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "\n",
      "[747 rows x 2 columns]\n",
      "\n",
      "DataFrame for Class ham:\n",
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "6         ham  Even my brother is not like to speak with me. ...\n",
      "...       ...                                                ...\n",
      "5565      ham                                       Huh y lei...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[4825 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separate data frames for individual classes (Class A and Class B)\n",
    "spam = df[df['Category'] == 'spam']\n",
    "ham = df[df['Category'] == 'ham']\n",
    "\n",
    "# Display the data frames\n",
    "print(\"DataFrame for Class spam:\")\n",
    "print(spam)\n",
    "\n",
    "print(\"\\nDataFrame for Class ham:\")\n",
    "print(ham)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "692a0679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for Class ham (Downsampled):\n",
      "     Category                                            Message\n",
      "3714      ham  If i not meeting ü all rite then i'll go home ...\n",
      "1311      ham  I.ll always be there, even if its just in spir...\n",
      "548       ham                   Sorry that took so long, omw now\n",
      "1324      ham  I thk 50 shd be ok he said plus minus 10.. Did...\n",
      "3184      ham  Dunno i juz askin cos i got a card got 20% off...\n",
      "...       ...                                                ...\n",
      "4992      ham  We made it! Eta at taunton is 12:30 as planned...\n",
      "3117      ham                Uncle Abbey! Happy New Year. Abiola\n",
      "4975      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...\n",
      "3505      ham                          Will you be here for food\n",
      "1983      ham  Hey i will be late... i'm at amk. Need to drin...\n",
      "\n",
      "[747 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Downsample Class B to have the same number of samples as Class A\n",
    "ham_downsampled = ham.sample(n=len(spam), random_state=42)\n",
    "\n",
    "# Display the downsampled DataFrame for Class B\n",
    "print(\"DataFrame for Class ham (Downsampled):\")\n",
    "print(ham_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61cfa605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame:\n",
      "     Category                                            Message\n",
      "0        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "1        spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "2        spam  WINNER!! As a valued network customer you have...\n",
      "3        spam  Had your mobile 11 months or more? U R entitle...\n",
      "4        spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "...       ...                                                ...\n",
      "1489      ham  We made it! Eta at taunton is 12:30 as planned...\n",
      "1490      ham                Uncle Abbey! Happy New Year. Abiola\n",
      "1491      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...\n",
      "1492      ham                          Will you be here for food\n",
      "1493      ham  Hey i will be late... i'm at amk. Need to drin...\n",
      "\n",
      "[1494 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "all_downsampled = pd.concat([spam, ham_downsampled], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(\"Concatenated DataFrame:\")\n",
    "print(all_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5aacabdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message  Label\n",
      "0        spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
      "1        spam  FreeMsg Hey there darling it's been 3 week's n...      1\n",
      "2        spam  WINNER!! As a valued network customer you have...      1\n",
      "3        spam  Had your mobile 11 months or more? U R entitle...      1\n",
      "4        spam  SIX chances to win CASH! From 100 to 20,000 po...      1\n",
      "...       ...                                                ...    ...\n",
      "1489      ham  We made it! Eta at taunton is 12:30 as planned...      0\n",
      "1490      ham                Uncle Abbey! Happy New Year. Abiola      0\n",
      "1491      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...      0\n",
      "1492      ham                          Will you be here for food      0\n",
      "1493      ham  Hey i will be late... i'm at amk. Need to drin...      0\n",
      "\n",
      "[1494 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {'spam': 1, 'ham': 0}\n",
    "all_downsampled['Label'] = all_downsampled['Category'].apply(lambda x: label_mapping[x])\n",
    "\n",
    "# Display the updated DataFrame with the 'Label' column\n",
    "print(all_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4a5777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape - X_train: (1195, 1) y_train: (1195,)\n",
      "Testing set shape - X_test: (299, 1) y_test: (299,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Features (X) are all the columns except 'Category' and 'Label'\n",
    "X = all_downsampled.drop(columns=['Category', 'Label'])\n",
    "\n",
    "# Labels (y) are contained in the 'Label' column\n",
    "y = all_downsampled['Label']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training set shape - X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"Testing set shape - X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75dfdad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Bored housewives! Chat n date now! 0871750.77....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>This is the 2nd time we have tried to contact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>ALRITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Promotion Number: 8714714 - UR awarded a City ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Message\n",
       "532   Bored housewives! Chat n date now! 0871750.77....\n",
       "534   This is the 2nd time we have tried to contact ...\n",
       "1108                                             ALRITE\n",
       "490   Promotion Number: 8714714 - UR awarded a City ...\n",
       "933   I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2b7a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the bert models for pre processing and encoding\n",
    "\n",
    "\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
    "\n",
    "                                                    \n",
    "\n",
    "\n",
    "# bert_preprocess =KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "# bert_encoder =KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6dacf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d9f6cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_6 (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_7 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer_6[0][0]',          \n",
      "                                None, 768),                       'keras_layer_6[0][1]',          \n",
      "                                 'encoder_outputs':               'keras_layer_6[0][2]']          \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_7[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c5736c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dccd2b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 205s 5s/step - loss: 0.4685 - accuracy: 0.8444\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 203s 5s/step - loss: 0.4143 - accuracy: 0.8678\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 195s 5s/step - loss: 0.3857 - accuracy: 0.8661\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 192s 5s/step - loss: 0.3564 - accuracy: 0.8795\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 191s 5s/step - loss: 0.3172 - accuracy: 0.8979\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 183s 5s/step - loss: 0.3087 - accuracy: 0.8946\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 179s 5s/step - loss: 0.2970 - accuracy: 0.9063\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 187s 5s/step - loss: 0.2809 - accuracy: 0.9096\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 210s 6s/step - loss: 0.2742 - accuracy: 0.9063\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 195s 5s/step - loss: 0.2646 - accuracy: 0.9079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f03cba86a0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebe3bba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 41s 4s/step - loss: 0.2939 - accuracy: 0.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29387134313583374, 0.8896321058273315]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e87700b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8073258 ],\n",
       "       [0.85586154],\n",
       "       [0.82312226],\n",
       "       [0.15896164],\n",
       "       [0.08310534]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "    'Reply to win Â£100 weekly! Where will the 2006 FIFA World Cup be held? Send STOP to 87239 to end service',\n",
    "    'You are awarded a SiPix Digital Camera! call 09061221061 from landline. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16 . p pÂ£3.99',\n",
    "    'it to 80488. Your 500 free text messages are valid until 31 December 2005.',\n",
    "    'Hey Sam, Are you coming for a cricket game tomorrow',\n",
    "    \"Why don't you wait 'til at least wednesday to see if you get your .\"\n",
    "]\n",
    "\n",
    "\n",
    "model.predict(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf7d7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('email_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b26ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 366). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2cead0b8-4431-47b9-b08f-f7232ba1eed8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2cead0b8-4431-47b9-b08f-f7232ba1eed8/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Saving model to disk\n",
    "pickle.dump(model, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec6ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
