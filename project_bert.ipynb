{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f9d39b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow_text==2.6.0 (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow_text==2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_text==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa4dd70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_text\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtext\u001b[39;00m    \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# !pip install --user tensorflow_text\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# !pip install tensorflow_hub\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_text'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import tensorflow_text as text    \n",
    "\n",
    "# !pip install --user tensorflow_text\n",
    "\n",
    "\n",
    "# !pip install tensorflow_hub\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import tensorflow_text as text    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:/Users/akash/Python_DL/project_data/Data.csv')\n",
    "# \"C:\\Users\\akash\\Python_DL\\project_data\\Data.csv\"\n",
    "df.head(5)\n",
    "\n",
    "df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "172b4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e679208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class KerasLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, hub_url, **kwargs):\n",
    "#         super(KerasLayer, self).__init__(**kwargs)\n",
    "#         self.hub_url = hub_url\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.bert_layer = hub.KerasLayer(self.hub_url, trainable=True)\n",
    "#         super(KerasLayer, self).build(input_shape)\n",
    "\n",
    "#     def call(self, inputs, **kwargs):\n",
    "#         return self.bert_layer(inputs, **kwargs)\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = super(KerasLayer, self).get_config()\n",
    "#         config['hub_url'] = self.hub_url\n",
    "#         return config\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_config(cls, config):\n",
    "#         return cls(hub_url=config['hub_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2fdb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for Class spam:\n",
      "     Category                                            Message\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "5        spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "8        spam  WINNER!! As a valued network customer you have...\n",
      "9        spam  Had your mobile 11 months or more? U R entitle...\n",
      "11       spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "...       ...                                                ...\n",
      "5537     spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540     spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547     spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566     spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "\n",
      "[747 rows x 2 columns]\n",
      "\n",
      "DataFrame for Class ham:\n",
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "6         ham  Even my brother is not like to speak with me. ...\n",
      "...       ...                                                ...\n",
      "5565      ham                                       Huh y lei...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[4825 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separate data frames for individual classes (Class A and Class B)\n",
    "spam = df[df['Category'] == 'spam']\n",
    "ham = df[df['Category'] == 'ham']\n",
    "\n",
    "# Display the data frames\n",
    "print(\"DataFrame for Class spam:\")\n",
    "print(spam)\n",
    "\n",
    "print(\"\\nDataFrame for Class ham:\")\n",
    "print(ham)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "692a0679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for Class ham (Downsampled):\n",
      "     Category                                            Message\n",
      "3714      ham  If i not meeting ü all rite then i'll go home ...\n",
      "1311      ham  I.ll always be there, even if its just in spir...\n",
      "548       ham                   Sorry that took so long, omw now\n",
      "1324      ham  I thk 50 shd be ok he said plus minus 10.. Did...\n",
      "3184      ham  Dunno i juz askin cos i got a card got 20% off...\n",
      "...       ...                                                ...\n",
      "4992      ham  We made it! Eta at taunton is 12:30 as planned...\n",
      "3117      ham                Uncle Abbey! Happy New Year. Abiola\n",
      "4975      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...\n",
      "3505      ham                          Will you be here for food\n",
      "1983      ham  Hey i will be late... i'm at amk. Need to drin...\n",
      "\n",
      "[747 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Downsample Class B to have the same number of samples as Class A\n",
    "ham_downsampled = ham.sample(n=len(spam), random_state=42)\n",
    "\n",
    "# Display the downsampled DataFrame for Class B\n",
    "print(\"DataFrame for Class ham (Downsampled):\")\n",
    "print(ham_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61cfa605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame:\n",
      "     Category                                            Message\n",
      "0        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "1        spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "2        spam  WINNER!! As a valued network customer you have...\n",
      "3        spam  Had your mobile 11 months or more? U R entitle...\n",
      "4        spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "...       ...                                                ...\n",
      "1489      ham  We made it! Eta at taunton is 12:30 as planned...\n",
      "1490      ham                Uncle Abbey! Happy New Year. Abiola\n",
      "1491      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...\n",
      "1492      ham                          Will you be here for food\n",
      "1493      ham  Hey i will be late... i'm at amk. Need to drin...\n",
      "\n",
      "[1494 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "all_downsampled = pd.concat([spam, ham_downsampled], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(\"Concatenated DataFrame:\")\n",
    "print(all_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aacabdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message  Label\n",
      "0        spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
      "1        spam  FreeMsg Hey there darling it's been 3 week's n...      1\n",
      "2        spam  WINNER!! As a valued network customer you have...      1\n",
      "3        spam  Had your mobile 11 months or more? U R entitle...      1\n",
      "4        spam  SIX chances to win CASH! From 100 to 20,000 po...      1\n",
      "...       ...                                                ...    ...\n",
      "1489      ham  We made it! Eta at taunton is 12:30 as planned...      0\n",
      "1490      ham                Uncle Abbey! Happy New Year. Abiola      0\n",
      "1491      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...      0\n",
      "1492      ham                          Will you be here for food      0\n",
      "1493      ham  Hey i will be late... i'm at amk. Need to drin...      0\n",
      "\n",
      "[1494 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {'spam': 1, 'ham': 0}\n",
    "all_downsampled['Label'] = all_downsampled['Category'].apply(lambda x: label_mapping[x])\n",
    "\n",
    "# Display the updated DataFrame with the 'Label' column\n",
    "print(all_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4a5777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape - X_train: (1195, 1) y_train: (1195,)\n",
      "Testing set shape - X_test: (299, 1) y_test: (299,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Features (X) are all the columns except 'Category' and 'Label'\n",
    "X = all_downsampled.drop(columns=['Category', 'Label'])\n",
    "\n",
    "# Labels (y) are contained in the 'Label' column\n",
    "y = all_downsampled['Label']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training set shape - X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"Testing set shape - X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75dfdad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Bored housewives! Chat n date now! 0871750.77....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>This is the 2nd time we have tried to contact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>ALRITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Promotion Number: 8714714 - UR awarded a City ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Message\n",
       "532   Bored housewives! Chat n date now! 0871750.77....\n",
       "534   This is the 2nd time we have tried to contact ...\n",
       "1108                                             ALRITE\n",
       "490   Promotion Number: 8714714 - UR awarded a City ...\n",
       "933   I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b7a657",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on MSI. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3746\u001b[0m, in \u001b[0;36mGraph.op_def_for_type\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   3745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3746\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n\u001b[0;32m   3747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Downloading the bert models for pre processing and encoding\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m bert_preprocess \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m bert_encoder \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:157\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mNoDependency(\n\u001b[0;32m    154\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m load_module(handle, tags, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_options)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hub_module_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:459\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m       set_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module_v2\u001b[38;5;241m.\u001b[39mload(handle, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39mset_load_options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    117\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(\n\u001b[0;32m    118\u001b[0m       module_path, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(module_path, tags\u001b[38;5;241m=\u001b[39mtags)\n\u001b[0;32m    121\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:858\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    857\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 858\u001b[0m result \u001b[38;5;241m=\u001b[39m load_partial(export_dir, \u001b[38;5;28;01mNone\u001b[39;00m, tags, options)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:988\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m    987\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 988\u001b[0m     loader \u001b[38;5;241m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    989\u001b[0m                     ckpt_options, options, filters)\n\u001b[0;32m    990\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    995\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:161\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proto \u001b[38;5;241m=\u001b[39m object_graph_proto\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_dir \u001b[38;5;241m=\u001b[39m export_dir\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 161\u001b[0m     function_deserialization\u001b[38;5;241m.\u001b[39mload_function_def_library(\n\u001b[0;32m    162\u001b[0m         library\u001b[38;5;241m=\u001b[39mmeta_graph\u001b[38;5;241m.\u001b[39mgraph_def\u001b[38;5;241m.\u001b[39mlibrary,\n\u001b[0;32m    163\u001b[0m         saved_object_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proto,\n\u001b[0;32m    164\u001b[0m         wrapper_function\u001b[38;5;241m=\u001b[39m_WrapperFunction))\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# captures.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restored_concrete_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:422\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# There is no need to copy all functions into the function def graph. It\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# leads to a O(n^2) increase of memory when importing functions and the\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# extra function definitions are a no-op since they already imported as a\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# function before and passed in explicitly (due to the topologic sort\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# import).\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 422\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m function_def_lib\u001b[38;5;241m.\u001b[39mfunction_def_to_graph(\n\u001b[0;32m    423\u001b[0m       fdef,\n\u001b[0;32m    424\u001b[0m       structured_input_signature\u001b[38;5;241m=\u001b[39mstructured_input_signature,\n\u001b[0;32m    425\u001b[0m       structured_outputs\u001b[38;5;241m=\u001b[39mstructured_outputs)\n\u001b[0;32m    426\u001b[0m \u001b[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# custom gradients)\u001b[39;00m\n\u001b[0;32m    428\u001b[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:91\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec, include_library_functions)\u001b[0m\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m         input_shapes\u001b[38;5;241m.\u001b[39mappend(input_shape)\n\u001b[1;32m---> 91\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[38;5;241m=\u001b[39m function_def_to_graph_def(\n\u001b[0;32m     92\u001b[0m     fdef, input_shapes, include_library_functions\u001b[38;5;241m=\u001b[39minclude_library_functions\n\u001b[0;32m     93\u001b[0m )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m     96\u001b[0m   \u001b[38;5;66;03m# Add all function nodes to the graph.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m   importer\u001b[38;5;241m.\u001b[39mimport_graph_def_for_function(\n\u001b[0;32m     98\u001b[0m       graph_def, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, propagate_device_spec\u001b[38;5;241m=\u001b[39mpropagate_device_spec)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:330\u001b[0m, in \u001b[0;36mfunction_def_to_graph_def\u001b[1;34m(fdef, input_shapes, include_library_functions)\u001b[0m\n\u001b[0;32m    328\u001b[0m       graph_def\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mgradient\u001b[38;5;241m.\u001b[39mextend([grad_def])\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m   op_def \u001b[38;5;241m=\u001b[39m default_graph\u001b[38;5;241m.\u001b[39mop_def_for_type(node_def\u001b[38;5;241m.\u001b[39mop)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m op_def\u001b[38;5;241m.\u001b[39mattr:\n\u001b[0;32m    333\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m attr\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3749\u001b[0m, in \u001b[0;36mGraph.op_def_for_type\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   3746\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n\u001b[0;32m   3747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   3748\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m op_def_pb2\u001b[38;5;241m.\u001b[39mOpDef\u001b[38;5;241m.\u001b[39mFromString(\n\u001b[1;32m-> 3749\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_for_type(\u001b[38;5;28mtype\u001b[39m)\n\u001b[0;32m   3750\u001b[0m   )\n\u001b[0;32m   3751\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on MSI. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed."
     ]
    }
   ],
   "source": [
    "# Downloading the bert models for pre processing and encoding\n",
    "\n",
    "\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
    "\n",
    "                                                    \n",
    "\n",
    "\n",
    "# bert_preprocess =KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "# bert_encoder =KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6dacf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d9f6cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_6 (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_7 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer_6[0][0]',          \n",
      "                                None, 768),                       'keras_layer_6[0][1]',          \n",
      "                                 'encoder_outputs':               'keras_layer_6[0][2]']          \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_7[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c5736c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dccd2b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 205s 5s/step - loss: 0.4685 - accuracy: 0.8444\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 203s 5s/step - loss: 0.4143 - accuracy: 0.8678\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 195s 5s/step - loss: 0.3857 - accuracy: 0.8661\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 192s 5s/step - loss: 0.3564 - accuracy: 0.8795\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 191s 5s/step - loss: 0.3172 - accuracy: 0.8979\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 183s 5s/step - loss: 0.3087 - accuracy: 0.8946\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 179s 5s/step - loss: 0.2970 - accuracy: 0.9063\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 187s 5s/step - loss: 0.2809 - accuracy: 0.9096\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 210s 6s/step - loss: 0.2742 - accuracy: 0.9063\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 195s 5s/step - loss: 0.2646 - accuracy: 0.9079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f03cba86a0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebe3bba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 41s 4s/step - loss: 0.2939 - accuracy: 0.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29387134313583374, 0.8896321058273315]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e87700b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8073258 ],\n",
       "       [0.85586154],\n",
       "       [0.82312226],\n",
       "       [0.15896164],\n",
       "       [0.08310534]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "    'Reply to win Â£100 weekly! Where will the 2006 FIFA World Cup be held? Send STOP to 87239 to end service',\n",
    "    'You are awarded a SiPix Digital Camera! call 09061221061 from landline. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16 . p pÂ£3.99',\n",
    "    'it to 80488. Your 500 free text messages are valid until 31 December 2005.',\n",
    "    'Hey Sam, Are you coming for a cricket game tomorrow',\n",
    "    \"Why don't you wait 'til at least wednesday to see if you get your .\"\n",
    "]\n",
    "\n",
    "\n",
    "model.predict(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf7d7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('email_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b26ca77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Saving model to disk\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mmodel\u001b[49m, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Saving model to disk\n",
    "pickle.dump(model, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ec6ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming 'model' is your Keras model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 6\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mmodel\u001b[49m, f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# To save the model\n",
    "import pickle\n",
    "\n",
    "# Assuming 'model' is your Keras model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebfe874",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (364810828.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af308f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
